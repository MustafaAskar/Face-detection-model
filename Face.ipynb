{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "jCaFc1hKz4uk"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import PIL\n",
    "import pickle\n",
    "import time \n",
    "import scipy\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "###################\n",
    "################\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.spatial import distance\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load FaceNet model\n",
    "FaceNet=tf.keras.models.load_model('facenet_keras.h5',compile=False)\n",
    "\n",
    "#load trained YOLO model\n",
    "config_path = \"yolov4-tiny.cfg\"\n",
    "weights_path = \"yolov4-tiny_2000.weights\"\n",
    "YOLO = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "ln = YOLO.getLayerNames()\n",
    "ln = [ln[i - 1] for i in YOLO.getUnconnectedOutLayers()]\n",
    "\n",
    "#specifiy the image size\n",
    "image_size = 160\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    #predefine some varabiles\n",
    "    size = x.size\n",
    "    axis = (0, 1, 2)\n",
    "    \n",
    "    #standardization\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    #l2 normalization\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def load_and_align_images(img,margin):\n",
    "    #to fix the bug of no detection\n",
    "    nms_boxes=[[0,0,0,0]]\n",
    "    \n",
    "    #empty the buffers\n",
    "    boxes, confidences, class_ids,names, aligned_images = [], [], [], [], []\n",
    "\n",
    "    #keep the original height and width, Caffe model require resizing to 300*300\n",
    "    h, w = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (160, 160), swapRB=True, crop=False)\n",
    "\n",
    "    #pass the image to the model\n",
    "    YOLO.setInput(blob)\n",
    "\n",
    "    #extract\n",
    "    faces = YOLO.forward(ln)\n",
    "    \n",
    "    # loop over each of the layer outputs\n",
    "    for output in faces:\n",
    "        # loop over each of the object detections\n",
    "        for detection in output:\n",
    "            # extract the confidence (as a probability) the current object detection\n",
    "            confidence = detection[5]\n",
    "            # discard weak predictions by ensuring the detected\n",
    "            # probability is greater than the minimum probability\n",
    "            if confidence > CONFIDENCE:\n",
    "                # scale the bounding box coordinates back relative to the\n",
    "                # size of the image, keeping in mind that YOLO actually\n",
    "                # returns the center (x, y)-coordinates of the bounding\n",
    "                # box followed by the boxes' width and height\n",
    "                box = detection[:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top and\n",
    "                # and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                x,y,width,height=abs(x)+2,abs(y)+2,abs(width)+2,abs(height)+2\n",
    "                \n",
    "                # update our list of bounding box coordinates, confidences\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                \n",
    "    # perform the non maximum suppression given the scores defined before\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_THRESHOLD, IOU_THRESHOLD)\n",
    "    \n",
    "    #loop over the suppressed boxes\n",
    "    if(len(idxs)>0):\n",
    "        nms_boxes=[]\n",
    "        for i in idxs.flatten():\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            #append new suppressed boxes to draw it\n",
    "            nms_boxes.append([x, y, int(w), int(h)])\n",
    "            face_cropped=img[y:y+h,x:x+w]\n",
    "            aligned = resize(face_cropped, (image_size, image_size), mode='reflect')\n",
    "            aligned_images.append(aligned)\n",
    "    return np.array(aligned_images), nms_boxes\n",
    "\n",
    "def calc_embs(img, margin=10, batch_size=1):\n",
    "    cropped_images, boxes=load_and_align_images(img, margin)\n",
    "    #to fix the bug of no detection\n",
    "    if(cropped_images.shape[0]!=0):\n",
    "        aligned_images = prewhiten(cropped_images)\n",
    "        embs = []\n",
    "        #calculate the emeddings\n",
    "        for start in range(0, len(aligned_images), batch_size):\n",
    "            pd=FaceNet.predict_on_batch(aligned_images[start:start+batch_size])\n",
    "            embs.append(l2_normalize(pd))\n",
    "    else:\n",
    "        embs=[np.zeros((128,1))]\n",
    "    return embs, boxes\n",
    "\n",
    "def calc_dist(img0, img1):\n",
    "    #calculate the distances\n",
    "    return distance.euclidean(img0, img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "R_T6vo-Ez0m8",
    "outputId": "b9136a41-689d-4ca3-9e7c-86be59887f97"
   },
   "outputs": [],
   "source": [
    "#pre definied varaiables\n",
    "CONFIDENCE = 0.5\n",
    "SCORE_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.4\n",
    "\n",
    "#load ref embeddings\n",
    "ref_embeddings=np.load('ref_embeddings.npy')\n",
    "\n",
    "#load ref names dict\n",
    "with open('ref_embeddings_names.pkl', 'rb') as f:\n",
    "    ref_embeddings_names = pickle.load(f)\n",
    "\n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "#define a timer to measure the performance\n",
    "start_time=time.time()\n",
    "\n",
    "while(True):\n",
    "    # Capture the video frame by frame    \n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    #calculate the embeddings and boxes\n",
    "    embeddings,boxes=calc_embs(frame)\n",
    "    \n",
    "    #loop over every embedding to calculate the distances\n",
    "    for i,embedding in enumerate(embeddings):\n",
    "        distances=[]\n",
    "        for j in range(len(ref_embeddings)):\n",
    "            dist=calc_dist(embedding,ref_embeddings[j])\n",
    "            distances.append(dist)\n",
    "\n",
    "            #choose the minimum distance and user\n",
    "            thersold_value=1\n",
    "            indexes=np.argmin(distances)\n",
    "            decision_value=distances[indexes]    \n",
    "            if decision_value > thersold_value:\n",
    "                name='Unknown'\n",
    "            else:      \n",
    "                name=ref_embeddings_names[indexes]\n",
    "\n",
    "            #draw the frame\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2,)          \n",
    "            cv2.putText(frame, name, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255,0,0), 2)\n",
    "\n",
    "    #measure the performance\n",
    "    cv2.putText(frame, str(int(1/(time.time()-start_time))), (0, 25), cv2.FONT_HERSHEY_SIMPLEX,1, (255,0,0), 2)\n",
    "    start_time=time.time()\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # the 'q' button is set as the\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dummy2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9860/2309598144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dummy2' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(dummy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TH6ICIFz_Kx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Face.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

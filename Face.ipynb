{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jCaFc1hKz4uk"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from scipy.spatial import distance\n",
    "import pickle\n",
    "###########################\n",
    "import mediapipe as mp\n",
    "##########################\n",
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Askar/.insightface\\models\\buffalo_sc\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\Askar/.insightface\\models\\buffalo_sc\\w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (160, 160)\n"
     ]
    }
   ],
   "source": [
    "# load mediapipe \n",
    "mp_facedetector = mp.solutions.face_detection\n",
    "detector=mp_facedetector.FaceDetection(min_detection_confidence=0.7)\n",
    "\n",
    "#load insight project\n",
    "app = FaceAnalysis(name='buffalo_sc',providers=['CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(160, 160))\n",
    "\n",
    "#load ref embeddings\n",
    "ref_embeddings=np.load('ref_embeddings.npy')\n",
    "\n",
    "#load ref names dict\n",
    "with open('ref_embeddings_names.pkl', 'rb') as f:\n",
    "    ref_embeddings_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "R_T6vo-Ez0m8",
    "outputId": "b9136a41-689d-4ca3-9e7c-86be59887f97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.24323654174805, 34.06298065185547, 22.673656463623047, 34.35149383544922, 34.9135627746582, 34.11944580078125]\n",
      "breaked\n",
      "[33.915283203125, 34.74393081665039, 20.883607864379883, 33.2120246887207, 32.88674545288086, 34.93144989013672]\n",
      "breaked\n"
     ]
    }
   ],
   "source": [
    "#performance and accuracy configurations\n",
    "refresh_period=1\n",
    "thersold_value=26\n",
    "\n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "#start the program\n",
    "while(True):\n",
    "    #empty the buffers\n",
    "    names_tracking=[]\n",
    "    \n",
    "    # Capture the video frame by frame    \n",
    "    _, frame = vid.read()\n",
    "    \n",
    "    #get the box and embeddings\n",
    "    faces=app.get(frame)\n",
    "    \n",
    "    if faces:\n",
    "        for i in range(len(faces)):\n",
    "            #select a face\n",
    "            face=faces[i]\n",
    "            #empty the buffer\n",
    "            distances=[]\n",
    "            #calculate the distance\n",
    "            for ref_embedding in ref_embeddings:\n",
    "                dist=distance.euclidean(face.embedding,ref_embedding)\n",
    "                distances.append(dist)\n",
    "            print(distances)\n",
    "            #choose the minimum distance and user\n",
    "            indexes=np.argmin(distances)\n",
    "            decision_value=distances[indexes]\n",
    "            #decide which user or unknown\n",
    "            if decision_value > thersold_value:\n",
    "                name='Unknown'\n",
    "                names_tracking.append(name)\n",
    "            else:      \n",
    "                name=ref_embeddings_names[indexes]\n",
    "                names_tracking.append(name)\n",
    "                \n",
    "#             #draw the frame\n",
    "#             frame = app.draw_on(frame, faces)\n",
    "#             cv2.putText(frame, name, (int(face.bbox[0])+20, int(face.bbox[1]) - 5), cv2.FONT_HERSHEY_SIMPLEX,0.6, (0,0,255), 2)\n",
    "\n",
    "#     #measure the performance\n",
    "#     cv2.putText(frame, str(int(1/(time.time()-start_time))), (0, 25), cv2.FONT_HERSHEY_SIMPLEX,1, (255,0,0), 2)\n",
    "#     start_time=time.time()\n",
    "\n",
    "#     #Display the resulting frame\n",
    "#     cv2.imshow('frame', frame)\n",
    "    \n",
    "    #track the faces\n",
    "    entry_names=len(names_tracking)\n",
    "    #start the software timer\n",
    "    software_timer=time.time()\n",
    "    while(True):\n",
    "        #empty the buffers\n",
    "        nms_boxes=[]\n",
    "        #measure the performance\n",
    "        start_time=time.time()\n",
    "        #detection using mediapipe\n",
    "        #capture frame\n",
    "        _, frame = vid.read()\n",
    "        # Convert the BGR image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Process the image and find faces\n",
    "        results = detector.process(image)\n",
    "        # Convert the image color back so it can be displayed\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.detections:\n",
    "            for id, detection in enumerate(results.detections):\n",
    "                bBox = detection.location_data.relative_bounding_box\n",
    "                h, w, c = image.shape\n",
    "                x,y,w,h=abs(int(bBox.xmin * w)), abs(int(bBox.ymin * h)-30), abs(int(bBox.width * w)), abs(int(bBox.height * h)+30)\n",
    "                nms_boxes.append([x, y, int(w), int(h)])\n",
    "        if entry_names!=len(nms_boxes) or (time.time()-software_timer)>refresh_period:\n",
    "            print('breaked')\n",
    "            break\n",
    "        else:\n",
    "            for i in range(len(nms_boxes)):\n",
    "                x, y = nms_boxes[i][0], nms_boxes[i][1]\n",
    "                w, h = nms_boxes[i][2], nms_boxes[i][3]\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2,)          \n",
    "                cv2.putText(frame, names_tracking[i], (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255,0,0), 2)\n",
    "        #measure the performance\n",
    "        cv2.putText(frame, str(int(1/(time.time()-start_time))), (0, 25), cv2.FONT_HERSHEY_SIMPLEX,1, (255,0,0), 2)\n",
    "        #Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # the 'q' button is set as the\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # the 'q' button is set as the\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Face.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
